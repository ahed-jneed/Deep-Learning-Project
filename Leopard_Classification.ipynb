{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Leopard Classification",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDcyoCfjnU6bVGSDYUDx6T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahed-jneed/Deep-Learning-Project/blob/main/Leopard_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qL2NDdsYT6H"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2yPXZhAAYX8"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6-JbWLdA2KH"
      },
      "source": [
        "from fastbook import *\n",
        "from fastai.vision.widgets import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcGhDo_-GpL4"
      },
      "source": [
        "# Downloaded the URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EWakf4SBTuT"
      },
      "source": [
        "results = search_images_ddg('african leopard')\n",
        "len(results), results[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVtHu7wXBT_E"
      },
      "source": [
        "dest = 'images/african.jpg'\n",
        "download_url(results[0], dest)\n",
        "im = Image.open(dest)\n",
        "im.thumbnail((128,128))\n",
        "im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDe1As4IGwy7"
      },
      "source": [
        "# Make a single File for each type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Snw4UWk3Sf"
      },
      "source": [
        "leopard_types = 'african','black','teddy'\n",
        "path = Path('leopard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHhRxep94o-f"
      },
      "source": [
        "if not path.exists():\n",
        "    path.mkdir()\n",
        "    for o in leopard_types:\n",
        "        dest = (path/o)\n",
        "        dest.mkdir(exist_ok=True)\n",
        "        results = search_images_ddg(f'{o} leopard')\n",
        "        download_images(dest, urls=results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q55cRA7vlco2"
      },
      "source": [
        "fns = get_image_files(path)\n",
        "fns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeHItum45_er"
      },
      "source": [
        "failed = verify_images(fns)\n",
        "failed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu_7A1uS6Egl"
      },
      "source": [
        "failed.map(Path.unlink);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XJ0vZ-OICWG"
      },
      "source": [
        "## From Data to DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b23ukim2mAV-"
      },
      "source": [
        "leopards = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock), \n",
        "    get_items=get_image_files, \n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=Resize(128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6P8TvkOmAbx"
      },
      "source": [
        "dls = leopards.dataloaders(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LUayJYm6OyC"
      },
      "source": [
        "dls.valid.show_batch(max_n=20, nrows=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z1F31BIO40K"
      },
      "source": [
        "One thing to be aware of in this process: models can only reflect the data used to train them. And the world is full of biased data, which ends up reflected in, for example, DuckDuckGo Image Search (which we used to create our dataset).\n",
        "With this as our training data, you would end up not with a a balck leopard detector, but an Actor in a movie dressed as a black panther detector! Be sure to think carefully about the types of data that you might expect to see in practice in your application, and check carefully to ensure that all these types are reflected in your model's source data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDH9KiuFfIJD"
      },
      "source": [
        "leopards = leopards.new(item_tfms = Resize(128, ResizeMethod.Squish))\n",
        "dls = leopards.dataloaders(path)\n",
        "dls.valid.show_batch(max_n = 4, nrows = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gf9gPAuRU6j"
      },
      "source": [
        "By default Resize crops the images to fit a square shape of the size requested, using the full width or height. This can result in losing some important details. Alternatively, you can ask fastai to pad the images with zeros (black), or squish/stretch them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3I1qr7O2_RO"
      },
      "source": [
        "leopards = leopards.new(item_tfms = Resize(128, ResizeMethod.Pad, pad_mode = 'zeros' ))\n",
        "dls = leopards.dataloaders(path)\n",
        "dls.valid.show_batch(max_n = 4, nrows = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7VX3MEd2_qd"
      },
      "source": [
        "leopards = leopards.new(item_tfms =   RandomResizedCrop(128, min_scale = 0.3))\n",
        "dls = leopards.dataloaders(path)\n",
        "dls.train.show_batch(max_n = 4, nrows = 1, unique = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8oetvmg2_7H"
      },
      "source": [
        "leopards = leopards.new(item_tfms = Resize(128), batch_tfms = aug_transforms(mult = 2))\n",
        "dls = leopards.dataloaders(path)\n",
        "dls.train.show_batch(max_n = 8, nrows = 2, unique = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMiOsjwDRs0y"
      },
      "source": [
        "All of these approaches seem somewhat wasteful, or problematic. If we squish or stretch the images they end up as unrealistic shapes, leading to a model that learns that things look different to how they actually are, which we would expect to result in lower accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rWJOJHQR3HI"
      },
      "source": [
        "Instead, what inormally do in practice is to randomly select part of the image, and crop to just that part. On each epoch (which is one complete pass through all of our images in the dataset) we randomly select a different part of each image. This means that our model can learn to focus on, and recognize, different features in our images. It also reflects how images work in the real world: different photos of the same thing may be framed in slightly different ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DkaC7DZSQim"
      },
      "source": [
        "## Training our Model, and Using It to Clean our Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdqRx3OGSd28"
      },
      "source": [
        "We don't have a lot of data for our problem (150 pictures of each sort of bear at most), so to train our model, we'll use RandomResizedCrop with an image size of 224 px, which is fairly standard for image classification, and default aug_transforms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWkn8Ngd3AaS"
      },
      "source": [
        "leopards = leopards.new(\n",
        "    item_tfms = RandomResizedCrop(224, min_scale = 0.5),\n",
        "    batch_tfms = aug_transforms()\n",
        ")\n",
        "dls = leopards.dataloaders(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZPk19SN_Vok"
      },
      "source": [
        "learn = cnn_learner(dls, resnet18, metrics = error_rate)\n",
        "learn.fine_tune(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdFhphpwLXGI"
      },
      "source": [
        "Now let's see whether the mistakes the model is making are mainly thinking that blackes are teddies (that would be bad for safety!), or that african are black leopards, or something else. To visualize this, we can create a confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESO9aP-p_V2T"
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJbo5YLL_WHB"
      },
      "source": [
        "interp.plot_top_losses(5, nrows = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg4gVxecFaEN"
      },
      "source": [
        "## Let's clean our images\n",
        "as we can see the Model has predict the teddy black leopard as black leopard and there are many images are not the right place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDBcyCvoNhyO"
      },
      "source": [
        "cleaner = ImageClassifierCleaner(learn)\n",
        "cleaner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2EhCeZSNsfw"
      },
      "source": [
        "for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDVh9vZuVJx9"
      },
      "source": [
        "for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyrn3sq8Y4Bz"
      },
      "source": [
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU0lFEVMY4FT"
      },
      "source": [
        "path = Path()\n",
        "path.ls(file_exts='.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epNCepV1Y4IL"
      },
      "source": [
        "learn_inf = load_learner(path/'export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JeMpc4FTybs"
      },
      "source": [
        "When we're doing inference, we're generally just getting predictions for one image at a time. To do this, pass a filename to predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GE-JmwUY4Ld"
      },
      "source": [
        "learn_inf.predict('/content/images/african.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG3MYenBUTVB"
      },
      "source": [
        "This has returned three things: the predicted category in the same format you originally provided (in this case that's a string), the index of the predicted category, and the probabilities of each category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBQMsF1EZHrj"
      },
      "source": [
        "learn_inf.dls.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1Bg5VsGUfyw"
      },
      "source": [
        "## Creating a Notebook App from the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxBKmjerZH1D"
      },
      "source": [
        "btn_upload = widgets.FileUpload()\n",
        "btn_upload"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfqgzM7PZbwK"
      },
      "source": [
        "#btn_upload = SimpleNamespace(data = ['/content/imags.jpg'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6RjqkfCZlSj"
      },
      "source": [
        "img = PILImage.create(btn_upload.data[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVlaz63MU68s"
      },
      "source": [
        "We can use an Output widget to display it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8lbMS0DZlUZ"
      },
      "source": [
        "out_pl = widgets.Output()\n",
        "out_pl.clear_output()\n",
        "with out_pl: display(img.to_thumb(128,128))\n",
        "out_pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbFJEE00ZlYC"
      },
      "source": [
        "pred,pred_idx,probs = learn_inf.predict(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP0NbtYgVKyb"
      },
      "source": [
        "and use a Label to display them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9YhiIUkZla5"
      },
      "source": [
        "lbl_pred = widgets.Label()\n",
        "lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
        "lbl_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlQNct2qVwZQ"
      },
      "source": [
        "We'll need a button to do the classification. It looks exactly like the upload button:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afKsUauWZ6BE"
      },
      "source": [
        "btn_run = widgets.Button(description='Classify')\n",
        "btn_run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5JNTQH2WPJ-"
      },
      "source": [
        "We'll also need a click event handler; that is, a function that will be called when it's pressed. We can just copy over the lines of code from above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUWM5Qy9Z6DN"
      },
      "source": [
        "def on_click_classify(change):\n",
        "    img = PILImage.create(btn_upload.data[-1])\n",
        "    out_pl.clear_output()\n",
        "    with out_pl: display(img.to_thumb(128,128))\n",
        "    pred,pred_idx,probs = learn_inf.predict(img)\n",
        "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
        "\n",
        "btn_run.on_click(on_click_classify)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z28rgYmDZ6Gv"
      },
      "source": [
        "#Putting back btn_upload to a widget for next cell\n",
        "btn_upload = widgets.FileUpload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON71x5BrZ6JJ"
      },
      "source": [
        "#hide_output\n",
        "VBox([widgets.Label('Select your leopard!'), \n",
        "      btn_upload, btn_run, out_pl, lbl_pred])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}